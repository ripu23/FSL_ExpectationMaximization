{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reuters.fileids()\n",
    " \n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                            documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                           documents))\n",
    "# train_docs_id = train_docs_id[:1000]\n",
    "# test_docs_id = test_docs_id[:1000]\n",
    " \n",
    "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "# train_docs = train_docs[:1000]\n",
    "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "# test_docs = test_docs[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769\n",
      "3019\n"
     ]
    }
   ],
   "source": [
    "print(len(train_docs))\n",
    "\n",
    "print(len(test_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:951: UserWarning: unknown class(es) ['cotton-oil', 'groundnut', 'groundnut-oil', 'l-cattle', 'lin-oil', 'oat', 'palladium', 'palm-oil', 'platinum', 'potato', 'retail', 'soy-meal', 'sun-meal', 'wpi'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                  for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id)\n",
    "                             for doc_id in test_docs_id])\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
    "vectorised_test_documents = vectorizer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(vectorised_train_documents, train_labels)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(vectorised_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.342"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.561"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(vectorised_train_documents, train_labels)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(vectorised_test_documents)\n",
    "\n",
    "accuracy_score(test_labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "categories = reuters.categories()\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2877\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "t = reuters.fileids('earn')\n",
    "f = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                            t))\n",
    "print(len(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
