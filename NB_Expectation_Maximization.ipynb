{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = skd.load_files('dataset/20Newsgroups/20news-bydate/20news-bydate-train', encoding='ISO-8859-1')\n",
    "\n",
    "test_data = skd.load_files('dataset/20Newsgroups/20news-bydate/20news-bydate-test', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorization\n",
    "count_vk = CountVectorizer()\n",
    "X_train_tf = count_vk.fit_transform(train_data.data)\n",
    "X_test_tf = count_vk.transform(test_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf (11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "tf = TfidfTransformer()\n",
    "X_train_tfidf = tf.fit_transform(X_train_tf)\n",
    "print('Shape of X_train_tfidf', X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131, 130107) (10183, 130107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.1 # labeled vs unlabeled\n",
    "X_l, X_u, y_l, y_u = train_test_split(X_train_tfidf, train_data.target, train_size=split_ratio, stratify=train_data.target)\n",
    "print(X_l.shape, X_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semiSupFit(X_l, y_l, X_u):\n",
    "    n_ul_docs = X_u.shape[0] # number of unlabeled samples\n",
    "    n_l_docs = X_l.shape[0] # number of labeled samples\n",
    "    alpha = 1e-2\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    clf.fit(X_l, y_l) # use labeled data only to initialize classifier parameters\n",
    "\n",
    "    theta_wt_cj = clf.feature_log_prob_ # log CP of word given class [n_classes, n_words]\n",
    "    theta_cj = clf.class_log_prior_\n",
    "    prev_theta_wt_cj = np.zeros(theta_wt_cj.shape) - np.inf # log CP of word given class [n_classes, n_words]\n",
    "    prev_theta_cj = np.zeros(theta_cj.shape) - np.inf\n",
    "    diff_wt_cj = np.sum(theta_wt_cj-prev_theta_wt_cj)\n",
    "    diff_cj = np.sum(theta_cj-prev_theta_cj)\n",
    "    totalDiff = diff_wt_cj+diff_cj\n",
    "    print(\"diff_wt_cj:\",diff_wt_cj,\"diff_cj:\",diff_cj,'totalDiff:',totalDiff)\n",
    "\n",
    "    iter_count = 0 # count EM iteration\n",
    "    max_iter=30\n",
    "    while (totalDiff!=0 and iter_count<max_iter):\n",
    "        iter_count += 1\n",
    "        print(\"EM iteration #%d\" % iter_count) # debug\n",
    "        # E-step: Estimate class membership of unlabeled documents\n",
    "        y_u = clf.predict(X_u)\n",
    "        # M-step: Re-estimate classifier parameters\n",
    "        X = vstack([X_l, X_u])\n",
    "        y = np.concatenate((y_l, y_u), axis=0)\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        theta_wt_cj = clf.feature_log_prob_ # log CP of word given class [n_classes, n_words]\n",
    "        theta_cj = clf.class_log_prior_\n",
    "\n",
    "        diff_wt_cj = np.sum(theta_wt_cj-prev_theta_wt_cj)\n",
    "        diff_cj = np.sum(theta_cj-prev_theta_cj)\n",
    "        totalDiff = diff_wt_cj+diff_cj\n",
    "        print(\"diff_wt_cj:\",diff_wt_cj,\"diff_cj:\",diff_cj,'totalDiff:',totalDiff)\n",
    "        prev_theta_wt_cj = theta_wt_cj\n",
    "        prev_theta_cj = theta_cj\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy is 63.516 %\n",
      "diff_wt_cj: inf diff_cj: inf totalDiff: inf\n",
      "EM iteration #1\n",
      "diff_wt_cj: inf diff_cj: inf totalDiff: inf\n",
      "EM iteration #2\n",
      "diff_wt_cj: -5831.3499956728065 diff_cj: 0.01281469903627297 totalDiff: -5831.33718097377\n",
      "EM iteration #3\n",
      "diff_wt_cj: -1004.3791510275624 diff_cj: 0.0009926520284047058 totalDiff: -1004.378158375534\n",
      "EM iteration #4\n",
      "diff_wt_cj: -312.80898895595345 diff_cj: 0.001047318062941116 totalDiff: -312.8079416378905\n",
      "EM iteration #5\n",
      "diff_wt_cj: -157.83304980879694 diff_cj: 0.001229723137170069 totalDiff: -157.83182008565979\n",
      "EM iteration #6\n",
      "diff_wt_cj: 0.0 diff_cj: 0.0 totalDiff: 0.0\n",
      "EM algo Accuracy is 72.809 %\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier (imported) \n",
    "# using labeled data set only\n",
    "cv_clf = MultinomialNB(alpha=1e-2)\n",
    "cv_clf.fit(X_l, y_l)\n",
    "predicted = cv_clf.predict(X_test_tf)\n",
    "accuracy = accuracy_score(test_data.target, predicted) * 100\n",
    "print(\"MultinomialNB Accuracy is {0:0.3f} %\".format(accuracy))\n",
    "\n",
    "# Training based on EM algorithm \n",
    "# using labeled data set only\n",
    "cv_clf = semiSupFit(X_l, y_l, X_u)\n",
    "predicted = cv_clf.predict(X_test_tf)\n",
    "accuracy = accuracy_score(test_data.target, predicted) * 100\n",
    "print(\"EM algo Accuracy is {0:0.3f} %\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
